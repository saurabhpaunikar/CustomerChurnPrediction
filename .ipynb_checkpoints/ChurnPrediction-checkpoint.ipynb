{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns', 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_customer_id = test_df['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['churn_risk_score'].isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatinating train and test data\n",
    "# Train = 1 i.e Belongs to training data and 0 belongs to test data\n",
    "train_df['Train'] = 1\n",
    "test_df['Train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([train_df, test_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping 'security_no' colummn as it has all unique values\n",
    "new_data.drop('security_no', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping 'Name' colummn as it has all unique values\n",
    "new_data.drop('Name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "sns.countplot(new_data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "sns.countplot(new_data['age'], hue = new_data['Train'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['churn_risk_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['churn_risk_score'] = new_data['churn_risk_score'].replace(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "sns.countplot(new_data['churn_risk_score'], hue = new_data['Train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('gender', data = new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('gender',hue = 'churn_risk_score', data = new_data)\n",
    "# For Training Data as Test Data has no churn_risk_score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['churn_risk_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_df['region_category'], hue = train_df['churn_risk_score']>3)\n",
    "\n",
    "# In village region - around 2K out of 4700 people have churn rate > 3 i.e is around 43%\n",
    "# In City region - around 7K out of 12700 have churn rate > 3 i.e is around 55%\n",
    "# In Town Region - around 7500 out of 14128 have churn rate > 3 i.e is around 53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['region_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['membership_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_df['membership_category'])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "train_df['membership_category'].value_counts().plot.pie(autopct='%1.1f%%')\n",
    "\n",
    "# Around 23.7% People come in the category having Platinum Memebership and Premiuim Membership\n",
    "# Around 41.7% people come in the category having basic or No Memebership\n",
    "# Around 34.6% people come ine the category having Gold or Silver Memebership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(new_data['membership_category'], hue = new_data['churn_risk_score'])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers having No Membership or Basic Membership have HIGH churn_risk_score of 5\n",
    "Customers having Platinum or Premium Membership have churn_risk_score 3 or less than 3\n",
    "Customers having Gold or Silver Membership have churn_risk_score 3 or 4\n",
    "\n",
    "From these observation, we can conclude that customers having No Membership or Basic Membership have very high chances of unsubscribing the services. Whereas, Customers having Platinum or Premium Membership have very low chances of unsubscribing the services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joined_through_referral'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'joined_through_referral' has some missing values('?'), so we will fill it with yes or no depending on whether they have a 'referral_id ' or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['referral_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing xxxxxxxx by np.nan values\n",
    "#new_data['referral_id'] = new_data['referral_id'].replace('xxxxxxxx', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the '?' in 'joined_through_referral' by checking if it has a 'referral_id' or not.\n",
    "\n",
    "If a customer had a 'referral_id' then we replace '?' in 'joined_through_referral' by a 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joined_through_referral'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['referral_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(new_data.joined_through_referral, new_data.referral_id):\n",
    "    \n",
    "    if (i == '?') and (j != 'xxxxxxxx'):\n",
    "        new_data['joined_through_referral'] = new_data['joined_through_referral'].replace('?', 'Yes')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joined_through_referral'].value_counts()\n",
    "# now, we don't have any outlier in 'joined_through_referral' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joined_through_referral'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['referral_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop('referral_id', axis = 1, inplace = True)\n",
    "# dropping 'referral_id' column has it had a lot of missing values and we anyway have 'joined_through_referral' column to\n",
    "# give details, like whether the cutomer joined through a referral or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['preferred_offer_types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['preferred_offer_types'].value_counts().plot.pie(autopct='%1.1f%%')\n",
    "# There is equal percentages of customers enjoying different offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "sns.countplot(train_df['preferred_offer_types'], hue = train_df['churn_risk_score'])\n",
    "\n",
    "# Customers without offers have a slightly higher chances of having 'churn_risk_score' >=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['region_category'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(new_data['membership_category'], hue = new_data['region_category'])\n",
    "# In every 'membership_category', majority subscribers are from Town and City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('medium_of_operation:\\n',new_data['medium_of_operation'].value_counts())\n",
    "print('\\n internet_option: \\n',new_data['internet_option'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['medium_of_operation'].value_counts().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_of_operation_list = new_data['medium_of_operation'].value_counts().keys()\n",
    "medium_of_operation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['internet_option'].value_counts().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi = []\n",
    "fibrop = []\n",
    "mobiledt = []\n",
    "\n",
    "for i,j in zip(new_data.medium_of_operation, new_data.internet_option):\n",
    "        #print(i,j)\n",
    "        if j == 'Wi-Fi':\n",
    "            wifi.append(i)\n",
    "        elif j == 'Fiber_Optic':\n",
    "            fibrop.append(i)\n",
    "        elif j == 'Mobile_Data':\n",
    "            mobiledt.append(i)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fun(lst, name):\n",
    "    return lst.count(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = wifi\n",
    "print('wifi Users : \\n')\n",
    "name = 'Desktop'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = 'Smartphone'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = '?'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = 'Both'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "# Mobile Data\n",
    "lst = mobiledt\n",
    "print('\\nMobile Data Users : \\n')\n",
    "name = 'Desktop'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = 'Smartphone'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = '?'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = 'Both'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "# Fibre Optics\n",
    "lst = fibrop\n",
    "print('\\nFibre Optics Users : \\n')\n",
    "name = 'Desktop'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = 'Smartphone'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = '?'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) \n",
    "\n",
    "name = 'Both'\n",
    "print('{} has occurred {} times'.format(name, count_fun(lst, name))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each 'internet_option' we checked which type of 'medium_of_operation' is mostly used.\n",
    "\n",
    "For customers, whose 'medium_of_operation' = '?', we will replace '?' with the type of internet option mostly used.\n",
    "\n",
    "Majority People having 'internet_option' = 'Wi-Fi' has 'medium_of_operation' = 'Desktop', so replacing '?' by 'Desktop' in the Table\n",
    "\n",
    "Majority People having 'internet_option' = Fiber_Optic' has 'medium_of_operation' = 'Smartphone', so replacing '?' by 'Smartphone' in the Table\n",
    "\n",
    "Majority People having 'internet_option' = 'Mobile_Data' has 'medium_of_operation' = 'Smartphone', so replacing '?' by 'Smartphone' in the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(new_data['internet_option'], hue = new_data['medium_of_operation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[(new_data['medium_of_operation'] == '?') & (new_data['internet_option'] == 'Wi-Fi')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condt = (new_data['medium_of_operation'] == '?') & (new_data['internet_option'] == 'Wi-Fi')\n",
    "new_data['medium_of_operation'] = np.where((condt), 'Desktop', new_data['medium_of_operation'])\n",
    "\n",
    "condt = (new_data['medium_of_operation'] == '?') & (new_data['internet_option'] == 'Fiber_Optic')\n",
    "new_data['medium_of_operation'] = np.where((condt), 'Smartphone', new_data['medium_of_operation'])\n",
    "\n",
    "condt = (new_data['medium_of_operation'] == '?') & (new_data['internet_option'] == 'Mobile_Data')\n",
    "new_data['medium_of_operation'] = np.where((condt), 'Smartphone', new_data['medium_of_operation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['medium_of_operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['medium_of_operation'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx 47.2% of the subscribers have 'medium_of_operation' == Smartphones\n",
    "\n",
    "Approx 42.5% of the subscribers have 'medium_of_operation' == Desktop\n",
    "\n",
    "Approx 10.4% of the subscribers have 'medium_of_operation' == Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['churn_risk_score'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(new_data['medium_of_operation'], hue = new_data['churn_risk_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['internet_option'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(new_data['membership_category'], hue = new_data['medium_of_operation'])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_time_spent'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['avg_time_spent'])\n",
    "plt.xlim(-1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_time_spent'] < 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2650 rows, having 'avg_time_spent' < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_time_spent'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in new_data['avg_time_spent']:\n",
    "    time = str (val)\n",
    "    if '-' in  time:\n",
    "        splt = time.split('-')\n",
    "        #print(splt[1])\n",
    "        res = splt[1]\n",
    "        #print( float (res))\n",
    "        #print(new_data['avg_time_spent'][val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_sign(val):\n",
    "    time = str (val)\n",
    "    if '-' in  time:\n",
    "        splt = time.split('-')\n",
    "        res = splt[1]\n",
    "        #print(res)\n",
    "        #print(new_data['avg_time_spent'][val])\n",
    "        return float(res)\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_time_spent'] = new_data['avg_time_spent'].apply(change_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_time_spent'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['avg_time_spent'])\n",
    "plt.xlim(-1000,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that, there are negative values , which cannot be possible as time spent cannot be in negative - OUTLIERS\n",
    "\n",
    "Either we can drop the columns having negative values or Remove the '-' sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['days_since_last_login'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['days_since_last_login'])\n",
    "plt.xlim(-20,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that, there are negative values , which cannot be possible as days cannot be in negative - OUTLIERS\n",
    "\n",
    "Maximum people have 'days_since_last_login' between 5-25 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['days_since_last_login'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[new_data['days_since_last_login'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data['days_since_last_login'].mean()\n",
    "#condt = (new_data['medium_of_operation'] == '?') & (new_data['internet_option'] == 'Mobile_Data')\n",
    "#new_data['medium_of_operation'] = np.where((condt), 'Smartphone', new_data['medium_of_operation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3021 rows, having 'days_since_last_login' < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condt = new_data['days_since_last_login'] < 0\n",
    "condt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['days_since_last_login'] = np.where((condt), np.nan, new_data['days_since_last_login'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['days_since_last_login'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[new_data['days_since_last_login'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df[df['Age'] < 25].index, inplace = True)\n",
    "#new_data = new_data.drop(new_data.loc[new_data['days_since_last_login'] < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(new_data['days_since_last_login'])\n",
    "plt.xlim(-10,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['avg_transaction_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority 'avg_transaction_value' is between 1k - 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_transaction_value'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = new_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt.drop(new_data.loc[new_data['avg_frequency_login_days'] == 'Error'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['avg_frequency_login_days'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['avg_frequency_login_days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_frequency_login_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_frequency_login_days'] == 'Error'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_frequency_login_days'] == 'Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data['avg_frequency_login_days'] = new_data['avg_frequency_login_days'].replace('Error', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_frequency_login_days'] = new_data['avg_frequency_login_days'].replace('Error', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_frequency_login_days'] == 'Error'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['avg_frequency_login_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'avg_frequency_login_days' has negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_frequency_login_days'] = new_data['avg_frequency_login_days'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_frequency_login_days'] < 0 ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condt = new_data['avg_frequency_login_days'] < 0 \n",
    "new_data['avg_frequency_login_days'] = np.where((condt), np.nan, new_data['avg_frequency_login_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['avg_frequency_login_days']<0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_frequency_login_days'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_frequency_login_days'] = new_data['avg_frequency_login_days'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['avg_frequency_login_days'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['points_in_wallet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[new_data['points_in_wallet'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condt = new_data['points_in_wallet'] < 0\n",
    "condt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['points_in_wallet'] = np.where((condt), np.nan, new_data['points_in_wallet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[new_data['points_in_wallet'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data = new_data.drop(new_data.loc[new_data['points_in_wallet'] < 0].index)\n",
    "#new_data[new_data['points_in_wallet'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.distplot(new_data['points_in_wallet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['points_in_wallet'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['used_special_discount'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_df['used_special_discount'], hue = train_df['churn_risk_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['used_special_discount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['past_complaint'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['past_complaint'].value_counts().plot.pie(autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['past_complaint'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['past_complaint'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(new_data['past_complaint'], hue = new_data['churn_risk_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['complaint_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['complaint_status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the customers whose 'past_complaint' value is 'No', their 'complaint_status' value is 'Not Applicable'\n",
    "\n",
    "For all the customers whose 'past_complaint' value is 'Yes', their 'complaint_status' value is either of [Solved in Follow-up, No Information Available, Unsolved, Solved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7)) \n",
    "new_data['complaint_status'].value_counts().plot.pie(autopct = '%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 5)) \n",
    "sns.countplot(new_data['complaint_status'], hue = new_data['churn_risk_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['feedback'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['feedback'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "new_data['feedback'].value_counts().plot.pie(autopct = '%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(new_data['feedback'], hue = new_data['churn_risk_score'])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers with feedback - [ 'Products always in Stock', 'Quality Customer Care', 'User Friendly Website', 'Reasonable Price' ] sums to 15.1%. That means only 15.1% of the customers with this feedback has 'churn_risk_score' value < 3.\n",
    "\n",
    "Customers with feedback - ['Poor Website', 'No reason specified', 'Poor Product Quality','Poor Customer Service', 'Too many ads',] sums to 84.9%. That means 84.9% of the customers with this feedback has 'churn_risk_score' value >= 3.\n",
    "\n",
    "We can make an observation from this, that only 15% of the customers has given +ve feedback, and the other 85% has given negative feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before handling missing values, we will handle the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['gender'] = new_data['gender'].map({'F' : 0, 'M' : 1, 'Unknown' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['region_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['region_category'] = new_data['region_category'].map({'Town' : 0, 'City' : 1, 'Village' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['membership_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['membership_category'] = new_data['membership_category'].map({'Basic Membership' : 0, \n",
    "                                                                       'No Membership' : 1, \n",
    "                                                                       'Gold Membership' : 2,\n",
    "                                                                       'Silver Membership' : 3,\n",
    "                                                                       'Premium Membership' : 4,\n",
    "                                                                       'Platinum Membership' : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joined_through_referral'] = new_data['joined_through_referral'].map({'Yes' : 0, 'No' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['preferred_offer_types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['preferred_offer_types'] = new_data['preferred_offer_types'].map({'Credit/Debit Card Offers' : 0, \n",
    "                                                                           'Gift Vouchers/Coupons' : 1, \n",
    "                                                                           'Without Offers' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['medium_of_operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['medium_of_operation'] = new_data['medium_of_operation'].map({'Smartphone' : 0, \n",
    "                                                                           'Desktop' : 1, \n",
    "                                                                           'Both' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['internet_option'] = new_data['internet_option'].map({'Fiber_Optic' : 0,'Wi-Fi' : 1,'Mobile_Data' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['used_special_discount'] = new_data['used_special_discount'].map({'Yes' : 0,'No' : 1})\n",
    "new_data['offer_application_preference'] = new_data['offer_application_preference'].map({'Yes' : 0,'No' : 1})\n",
    "new_data['past_complaint'] = new_data['past_complaint'].map({'Yes' : 0,'No' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['complaint_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['complaint_status'] = new_data['complaint_status'].map({'Not Applicable' : 0,'Solved in Follow-up' : 1, \n",
    "                                                              'No Information Available' : 2,'Unsolved' : 3, 'Solved' : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "new_data['feedback'] = le.fit_transform(new_data['feedback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['feedback'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop('customer_id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splt_fun_year(val):\n",
    "    x = val.split('-')\n",
    "    return x[0]\n",
    "\n",
    "def splt_fun_month(val):\n",
    "    x = val.split('-')\n",
    "    return x[1]\n",
    "\n",
    "def splt_fun_day(val):\n",
    "    x = val.split('-')\n",
    "    return x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joining_date_year'] = new_data['joining_date'].apply(splt_fun_year)\n",
    "new_data['joining_date_month'] = new_data['joining_date'].apply(splt_fun_month)\n",
    "new_data['joining_date_day'] = new_data['joining_date'].apply(splt_fun_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop('joining_date', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['joining_date_year'] = new_data['joining_date_year'].astype(int)\n",
    "new_data['joining_date_month'] = new_data['joining_date_month'].astype(int)\n",
    "new_data['joining_date_day'] = new_data['joining_date_day'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['last_visit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splt_fun_hr(val):\n",
    "    x = val.split(':')\n",
    "    return x[0]\n",
    "\n",
    "def splt_fun_min(val):\n",
    "    x = val.split(':')\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['last_visit_hour'] = new_data['last_visit_time'].apply(splt_fun_hr)\n",
    "new_data['last_visit_min'] = new_data['last_visit_time'].apply(splt_fun_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop('last_visit_time',axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['last_visit_hour'] = new_data['last_visit_hour'].astype(int)\n",
    "new_data['last_visit_min'] = new_data['last_visit_min'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=3, missing_values=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['churn_risk_score'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = new_data.loc[new_data['churn_risk_score'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data_train = pd.DataFrame(np.round(imputer.fit_transform(train_data)),columns = train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = encode_data_train\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Train', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['churn_risk_score'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = new_data.loc[new_data['churn_risk_score'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop('churn_risk_score', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop('Train', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data_test = pd.DataFrame(np.round(imputer.fit_transform(test_df)),\n",
    "                           columns = test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = encode_data_test\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,10))\n",
    "sns.heatmap(train_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that few independent variables shows strong negative correlations(>0.7), so we will drop either one of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.corr()['churn_risk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,10))\n",
    "sns.heatmap(test_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,10))\n",
    "sns.heatmap(train_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['churn_risk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_train_data = train_df\n",
    "saved_test_data = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Our data is ready for training. So, we will split the training and testing data from the new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['last_visit_hour','last_visit_min'], axis = 1, inplace = True)\n",
    "test_df.drop(['last_visit_hour','last_visit_min'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['used_special_discount','complaint_status'], axis = 1, inplace = True)\n",
    "test_df.drop(['used_special_discount','complaint_status'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.drop('churn_risk_score', axis = 1)\n",
    "y = train_data['churn_risk_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 101, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(random_state = 100)\n",
    "xgb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ypred = xgb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, xgb_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(criterion= 'entropy', n_estimators = 90,random_state=100)\n",
    "rf_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ypred = rf_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, rf_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sc = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_sc = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(xtrain_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_ypred = knn_classifier.predict(xtest_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, knn_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='rbf', random_state = 10)\n",
    "svm_classifier.fit(xtrain_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ypred = svm_classifier.predict(xtest_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, svm_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(objective='multi', random_state=1, n_jobs=-1, \n",
    "                               learning_rate=0.15, \n",
    "                               n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ypred = lgb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, lgb_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_classifier = cb.CatBoostClassifier(verbose=0, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_classifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_ypred = cb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, cb_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xgb_classifier = XGBClassifier(n_estimators = 103,\n",
    "                                          min_child_weight = 10,\n",
    "                                          gamma =  0.1,\n",
    "                                          learning_rate = 0.01,\n",
    "                                          max_depth = 149,\n",
    "                                          subsample = 0.7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xgb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xgb_ypred = new_xgb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, new_xgb_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rf_classifier = RandomForestClassifier(n_estimators = 217,\n",
    "                                          min_samples_split = 9,\n",
    "                                          min_samples_leaf =  1,\n",
    "                                          max_features = 'log2',\n",
    "                                          max_depth = 16,\n",
    "                                          criterion = 'entropy',\n",
    "                                           class_weight='balanced_subsample',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rf_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rg_ypred = new_rf_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 100 * f1_score(y_test, new_rg_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform as sp_uniform\n",
    "param_grid = {\n",
    "             'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(10, 300), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100, 150, 200],\n",
    "    \n",
    "             #'max_depth': sp_randint(5,100), #add\n",
    "             #'n_estimators':sp_randint(10,300,50),  #add           \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lgb_classifier = lgb.LGBMClassifier(colsample_bytree=0.6891239292918483,\n",
    "                                           min_child_samples=295,\n",
    "                                           min_child_weight=10,\n",
    "                                           num_leaves = 6,\n",
    "                                           reg_alpha = 10,\n",
    "                                           reg_lambda = 150,\n",
    "                                           subsample = 0.8721158617161302,\n",
    "                                            #max_depth = 53\n",
    "                                        )\n",
    "\n",
    "new_lgb_classifier.fit(x_train, y_train)\n",
    "new_lgb_ypred = new_lgb_classifier.predict(x_test)\n",
    "score = 100 * f1_score(y_test, new_lgb_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_cb_classifier = cb.CatBoostClassifier(max_depth = 5,\n",
    "                                         learning_rate = 0.08,\n",
    "                                         l2_leaf_reg = 4,\n",
    "                                         iterations = 100,\n",
    "                                         colsample_bylevel = 0.7000000000000002)\n",
    "\n",
    "new_cb_classifier.fit(x_train, y_train)\n",
    "new_cb_ypred = new_cb_classifier.predict(x_test)\n",
    "score = 100 * f1_score(y_test, new_cb_ypred, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_csv = new_lgb_classifier.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(columns=['customer_id', 'churn_risk_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['churn_risk_score'] = sub_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['customer_id'] = test_customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
